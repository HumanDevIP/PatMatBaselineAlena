{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # code required by Colab\n",
    "    %cd /content/drive/MyDrive/PatMatBaselineAlena\n",
    "\n",
    "    root_dir = '/content/drive/MyDrive/PatMatBaselineAlena'\n",
    "else:\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith(\"notebooks\"):\n",
    "        root_dir = '..'\n",
    "        %cd ..\n",
    "    else:\n",
    "        root_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alena\\MyFolder\\DIL\\PatMatBaselineAlena\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'data/train.parquet'\n",
    "test_file_path = 'data/test.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(train_file_path)\n",
    "df_test = pd.read_parquet(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808, 3030)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21052631578947367"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test) / (len(df_test) + len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 0.0924092409240924\n"
     ]
    }
   ],
   "source": [
    "rows_with_nulls_train = df_train[df_train.isna().any(axis=1)]\n",
    "print(len(rows_with_nulls_train), len(rows_with_nulls_train)/len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 0.09158415841584158\n"
     ]
    }
   ],
   "source": [
    "rows_with_nulls_test = df_test[df_test.isna().any(axis=1)]\n",
    "print(len(rows_with_nulls_test), len(rows_with_nulls_test)/len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 0.030033003300330034\n"
     ]
    }
   ],
   "source": [
    "rows_with_nulls_train_columns_needed = df_train[df_train[['text', 'text_b', 'label']].isna().any(axis=1)]\n",
    "print(len(rows_with_nulls_train_columns_needed), len(rows_with_nulls_train_columns_needed)/len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0.03094059405940594\n"
     ]
    }
   ],
   "source": [
    "rows_with_nulls_test_columns_needed = df_test[df_test[['text', 'text_b', 'label']].isna().any(axis=1)]\n",
    "print(len(rows_with_nulls_test_columns_needed), len(rows_with_nulls_test_columns_needed)/len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and filtering of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_filtered = df_train[df_train[['text', 'text_b', 'label']].notna().all(axis=1)]\n",
    "\n",
    "len(df_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 2939, 58, 0.01914191419141914)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_train = df_train_filtered.duplicated(subset=[\"text\", \"text_b\"], keep=False)\n",
    "num_duplicates_train = duplicates_train.sum()\n",
    "cleaned_df_train = df_train_filtered[~duplicates_train]\n",
    "len(cleaned_df_train), len(duplicates_train), num_duplicates_train, num_duplicates_train / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    1683\n",
       "0.0    1198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = cleaned_df_train['label'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning and filtering of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_filtered = df_test[df_test[['text', 'text_b', 'label']].notna().all(axis=1)]\n",
    "\n",
    "len(df_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(769, 783, 14, 0.017326732673267328)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_test = df_test_filtered.duplicated(subset=[\"text\", \"text_b\"], keep=False)\n",
    "num_duplicates_test = duplicates_test.sum()\n",
    "cleaned_df_test = df_test_filtered[~duplicates_test]\n",
    "len(cleaned_df_test), len(duplicates_test), num_duplicates_test, num_duplicates_test/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    394\n",
       "1.0    375\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = cleaned_df_test['label'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates in the test set that are present in the training set\n",
    "duplicates_test = cleaned_df_test.merge(cleaned_df_train, on=[\"text\", \"text_b\"], how=\"inner\")\n",
    "len(duplicates_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_for_split = cleaned_df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df, validation_df = train_test_split(df_train_for_split, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['text', 'text_b', 'label']]\n",
    "validation_df = validation_df[['text', 'text_b', 'label']]\n",
    "test_df = cleaned_df_test[['text', 'text_b', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304 0.6312328767123287\n",
      "577 0.15808219178082192\n",
      "769 0.2106849315068493\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(train_df) / sum([len(train_df), len(validation_df), len(test_df)]))\n",
    "print(len(validation_df), len(validation_df) / sum([len(train_df), len(validation_df), len(test_df)]))\n",
    "print(len(test_df), len(test_df) / sum([len(train_df), len(validation_df), len(test_df)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The medical device of claim 1 wherein said hou...</td>\n",
       "      <td>In one embodiment the device also includes at ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Process according to any one of the preceding ...</td>\n",
       "      <td>According to another embodiment the white pigm...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The method of any of claims 11 to 12 further c...</td>\n",
       "      <td>In certain embodiments the method further comp...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A gas turbine engine 20 comprising an engine s...</td>\n",
       "      <td>Referring now to FIG.6 an axial section view o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The system of claim 1 the operations comprisin...</td>\n",
       "      <td>Each of the entry and exit gates 202 204 compr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The medical device of claim 1 wherein said hou...   \n",
       "1  Process according to any one of the preceding ...   \n",
       "2  The method of any of claims 11 to 12 further c...   \n",
       "3  A gas turbine engine 20 comprising an engine s...   \n",
       "4  The system of claim 1 the operations comprisin...   \n",
       "\n",
       "                                              text_b  label  \n",
       "0  In one embodiment the device also includes at ...    1.0  \n",
       "1  According to another embodiment the white pigm...    0.0  \n",
       "2  In certain embodiments the method further comp...    0.0  \n",
       "3  Referring now to FIG.6 an axial section view o...    1.0  \n",
       "4  Each of the entry and exit gates 202 204 compr...    0.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(df, filename):\n",
    "    df.to_json(filename, orient='records', lines=True)\n",
    "\n",
    "save_to_jsonl(train_df, '../data/train.jsonl')\n",
    "save_to_jsonl(validation_df, '../data/validation.jsonl')\n",
    "save_to_jsonl(test_df, '../data/test.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
